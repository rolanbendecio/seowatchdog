{
  "name": "SEO Watchdog - Batched Processing",
  "description": "Optimized SEO monitoring workflow with batch processing for large datasets",
  "version": "2.1",
  "nodes": [
    {
      "parameters": {
        "rule": {
          "interval": [
            {
              "field": "cronExpression",
              "value": "0 9 * * *"
            }
          ]
        }
      },
      "id": "scheduler",
      "name": "Daily Schedule",
      "type": "n8n-nodes-base.cron",
      "typeVersion": 1,
      "position": [240, 300],
      "notes": "üïò SCHEDULER: Triggers workflow daily at 9 AM with batch processing"
    },
    {
      "parameters": {
        "jsCode": "// üî¢ BATCH CONFIGURATION\n// Configure batch sizes to prevent timeouts\n\nconst batchConfig = {\n  // üìä BATCH SIZES (adjust based on your data volume)\n  performance_batch_size: 100,    // Process 100 pages at a time\n  keywords_batch_size: 50,        // Process 50 keywords per batch\n  indexing_batch_size: 100,       // Process 100 indexing records\n  \n  // ‚è±Ô∏è TIMING CONFIGURATION\n  batch_delay: 2000,              // 2 second delay between batches\n  query_timeout: 30000,           // 30 second timeout per query\n  \n  // üìÖ DATE RANGE LIMITS\n  max_days_back: 30,              // Limit to 30 days of data\n  \n  // üéØ PERFORMANCE LIMITS\n  max_total_records: 1000,        // Maximum records to process\n  priority_threshold: 1000        // Minimum impressions for priority\n};\n\n// üìã Create batch processing metadata\nconst batchMetadata = {\n  batch_config: batchConfig,\n  execution_id: `seo_batch_${Date.now()}`,\n  start_time: new Date().toISOString(),\n  date_range: {\n    start_date: new Date(Date.now() - (batchConfig.max_days_back * 24 * 60 * 60 * 1000)).toISOString().split('T')[0],\n    end_date: new Date(Date.now() - (24 * 60 * 60 * 1000)).toISOString().split('T')[0]\n  }\n};\n\nreturn { json: batchMetadata };"
      },
      "id": "batch_config",
      "name": "Batch Configuration",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [460, 300],
      "notes": "üî¢ BATCH CONFIGURATION\n\nüéØ PURPOSE:\n‚Ä¢ Sets batch sizes to prevent timeouts\n‚Ä¢ Configures processing limits\n‚Ä¢ Defines date ranges\n‚Ä¢ Creates execution metadata\n\nüìä BATCH SIZES:\n‚Ä¢ Performance: 100 pages per batch\n‚Ä¢ Keywords: 50 keywords per batch\n‚Ä¢ Indexing: 100 records per batch\n\n‚è±Ô∏è TIMING:\n‚Ä¢ 2 second delay between batches\n‚Ä¢ 30 second timeout per query\n‚Ä¢ Maximum 30 days of data\n\nüîß CUSTOMIZATION:\n‚Ä¢ Adjust batch sizes based on data volume\n‚Ä¢ Modify timeouts for your environment\n‚Ä¢ Change date ranges as needed"
    },
    {
      "parameters": {
        "authentication": "serviceAccount",
        "projectId": "={{ $env.GCP_PROJECT_ID }}",
        "query": "-- üìä OPTIMIZED PERFORMANCE QUERY WITH BATCHING\n-- This query uses pagination and limits to prevent timeouts\n\nWITH recent_data AS (\n  SELECT \n    date,\n    page,\n    query,\n    clicks,\n    impressions,\n    SAFE_DIVIDE(clicks, impressions) * 100 as ctr,\n    position,\n    device,\n    -- üéØ Add row numbers for pagination\n    ROW_NUMBER() OVER (ORDER BY impressions DESC, clicks DESC) as row_num\n  FROM `{{ $env.GCP_PROJECT_ID }}.searchconsole.searchdata_site_impression`\n  WHERE \n    date >= '{{ $json.date_range.start_date }}'\n    AND date <= '{{ $json.date_range.end_date }}'\n    AND impressions >= {{ $json.batch_config.priority_threshold }}  -- Focus on high-impression pages\n),\n\npage_performance AS (\n  SELECT \n    page,\n    SUM(clicks) as total_clicks,\n    SUM(impressions) as total_impressions,\n    SAFE_DIVIDE(SUM(clicks), SUM(impressions)) * 100 as avg_ctr,\n    AVG(position) as avg_position,\n    COUNT(DISTINCT query) as keyword_count,\n    DATE_DIFF(CURRENT_DATE(), MAX(date), DAY) as days_since_last_data\n  FROM recent_data\n  WHERE row_num <= {{ $json.batch_config.max_total_records }}  -- Limit total records\n  GROUP BY page\n),\n\ntraffic_trends AS (\n  SELECT \n    page,\n    DATE_TRUNC(date, WEEK) as week,\n    SUM(clicks) as weekly_clicks,\n    SUM(impressions) as weekly_impressions\n  FROM recent_data\n  WHERE row_num <= {{ $json.batch_config.max_total_records }}\n  GROUP BY page, week\n),\n\nweekly_comparison AS (\n  SELECT \n    page,\n    LAG(weekly_clicks, 1) OVER (PARTITION BY page ORDER BY week) as prev_week_clicks,\n    weekly_clicks as current_week_clicks,\n    SAFE_DIVIDE(weekly_clicks - LAG(weekly_clicks, 1) OVER (PARTITION BY page ORDER BY week), LAG(weekly_clicks, 1) OVER (PARTITION BY page ORDER BY week)) * 100 as click_change_percent\n  FROM traffic_trends\n  WHERE week = DATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 7 DAY), WEEK)\n)\n\n-- üéØ FINAL RESULTS: Limited and optimized\nSELECT \n  pp.page,\n  pp.total_clicks,\n  pp.total_impressions,\n  pp.avg_ctr,\n  pp.avg_position,\n  pp.keyword_count,\n  pp.days_since_last_data,\n  COALESCE(wc.click_change_percent, 0) as click_change_percent,\n  CASE \n    WHEN COALESCE(wc.click_change_percent, 0) < -20 THEN 'traffic_drop'\n    WHEN COALESCE(wc.click_change_percent, 0) > 20 THEN 'traffic_surge'\n    WHEN pp.avg_ctr < 2 AND pp.total_impressions > 1000 THEN 'low_ctr'\n    WHEN pp.avg_position > 10 AND pp.total_impressions > 500 THEN 'low_position'\n    WHEN pp.days_since_last_data > 7 THEN 'potential_deindex'\n    ELSE 'normal'\n  END as alert_type\nFROM page_performance pp\nLEFT JOIN weekly_comparison wc ON pp.page = wc.page\nORDER BY pp.total_clicks DESC\nLIMIT {{ $json.batch_config.performance_batch_size }}"
      },
      "id": "bigquery_performance_batch",
      "name": "BigQuery - Performance (Batched)",
      "type": "n8n-nodes-base.googleBigQuery",
      "typeVersion": 1,
      "position": [680, 200],
      "notes": "üìä BATCHED PERFORMANCE QUERY\n\nüéØ OPTIMIZATIONS:\n‚Ä¢ Row number pagination\n‚Ä¢ Impression threshold filtering\n‚Ä¢ Limited record processing\n‚Ä¢ Efficient date range filtering\n\nüìà PERFORMANCE FEATURES:\n‚Ä¢ Processes top 100 pages only\n‚Ä¢ Focuses on high-impression pages\n‚Ä¢ Uses efficient sorting\n‚Ä¢ Prevents timeout issues\n\nüîß BATCH CONTROLS:\n‚Ä¢ Configurable batch size\n‚Ä¢ Priority threshold filtering\n‚Ä¢ Maximum record limits\n‚Ä¢ Optimized query structure"
    },
    {
      "parameters": {
        "authentication": "serviceAccount",
        "projectId": "={{ $env.GCP_PROJECT_ID }}",
        "query": "-- üîç OPTIMIZED INDEXING QUERY WITH BATCHING\n-- Limits data processing to prevent timeouts\n\nWITH recent_crawl_data AS (\n  SELECT \n    page_url,\n    last_crawl_time,\n    coverage_state,\n    is_excluded,\n    DATE_DIFF(CURRENT_DATE(), DATE(last_crawl_time), DAY) as days_since_crawl,\n    -- üéØ Add row numbers for pagination\n    ROW_NUMBER() OVER (ORDER BY last_crawl_time DESC) as row_num\n  FROM `{{ $env.GCP_PROJECT_ID }}.searchconsole.crawl_stats`\n  WHERE \n    DATE(last_crawl_time) >= '{{ $json.date_range.start_date }}'\n    AND DATE(last_crawl_time) <= '{{ $json.date_range.end_date }}'\n),\n\nindexing_issues AS (\n  SELECT \n    page_url,\n    coverage_state,\n    is_excluded,\n    days_since_crawl,\n    CASE \n      WHEN is_excluded = FALSE AND coverage_state = 'Valid' THEN 'newly_indexed'\n      WHEN is_excluded = TRUE OR coverage_state != 'Valid' THEN 'deindexed'\n      WHEN days_since_crawl > 7 THEN 'crawl_issue'\n      ELSE 'normal'\n    END as indexing_status\n  FROM recent_crawl_data\n  WHERE row_num <= {{ $json.batch_config.indexing_batch_size }}  -- Limit processing\n)\n\n-- üéØ FINAL RESULTS: Only problematic pages\nSELECT \n  page_url,\n  coverage_state,\n  is_excluded,\n  days_since_crawl,\n  indexing_status,\n  COUNT(*) OVER (PARTITION BY indexing_status) as status_count\nFROM indexing_issues\nWHERE indexing_status != 'normal'\nORDER BY days_since_crawl DESC\nLIMIT {{ $json.batch_config.indexing_batch_size }}"
      },
      "id": "bigquery_indexing_batch",
      "name": "BigQuery - Indexing (Batched)",
      "type": "n8n-nodes-base.googleBigQuery",
      "typeVersion": 1,
      "position": [680, 400],
      "notes": "üîç BATCHED INDEXING QUERY\n\nüéØ OPTIMIZATIONS:\n‚Ä¢ Row number pagination\n‚Ä¢ Recent data focus\n‚Ä¢ Limited record processing\n‚Ä¢ Efficient sorting by crawl time\n\nüìà PERFORMANCE FEATURES:\n‚Ä¢ Processes latest 100 crawl records\n‚Ä¢ Filters out normal status\n‚Ä¢ Uses efficient date filtering\n‚Ä¢ Prevents timeout issues\n\nüîß BATCH CONTROLS:\n‚Ä¢ Configurable batch size\n‚Ä¢ Date range limiting\n‚Ä¢ Status filtering\n‚Ä¢ Optimized query structure"
    },
    {
      "parameters": {
        "jsCode": "// üîÑ BATCH DATA PROCESSING\n// Enhanced data combination with batch processing safeguards\n\ntry {\n  // üìä Extract data with null checks\n  const performanceData = $input.first()?.json || [];\n  const indexingData = $input.last()?.json || [];\n  \n  // üõ°Ô∏è Data validation\n  const validPerformanceData = Array.isArray(performanceData) ? performanceData : [];\n  const validIndexingData = Array.isArray(indexingData) ? indexingData : [];\n  \n  // üìã Process with batch information\n  const batchProcessedData = {\n    // üìä CORE DATA\n    performance_data: validPerformanceData,\n    indexing_data: validIndexingData,\n    \n    // üìÖ METADATA\n    analysis_date: new Date().toISOString().split('T')[0],\n    processing_time: new Date().toISOString(),\n    \n    // üî¢ BATCH STATISTICS\n    batch_info: {\n      performance_records: validPerformanceData.length,\n      indexing_records: validIndexingData.length,\n      total_records: validPerformanceData.length + validIndexingData.length,\n      batch_size_used: Math.min(validPerformanceData.length, 100),\n      processing_complete: true\n    },\n    \n    // üìä ENHANCED SUMMARY\n    summary: {\n      total_clicks: validPerformanceData.reduce((sum, page) => sum + (parseInt(page.total_clicks) || 0), 0),\n      total_impressions: validPerformanceData.reduce((sum, page) => sum + (parseInt(page.total_impressions) || 0), 0),\n      avg_ctr: validPerformanceData.length > 0 ? \n        validPerformanceData.reduce((sum, page) => sum + (parseFloat(page.avg_ctr) || 0), 0) / validPerformanceData.length : 0,\n      \n      // üö® ALERT COUNTS\n      alert_counts: {\n        traffic_drops: validPerformanceData.filter(p => p.alert_type === 'traffic_drop').length,\n        traffic_surges: validPerformanceData.filter(p => p.alert_type === 'traffic_surge').length,\n        low_ctr: validPerformanceData.filter(p => p.alert_type === 'low_ctr').length,\n        low_position: validPerformanceData.filter(p => p.alert_type === 'low_position').length,\n        potential_deindex: validPerformanceData.filter(p => p.alert_type === 'potential_deindex').length,\n        normal: validPerformanceData.filter(p => p.alert_type === 'normal').length\n      },\n      \n      // üîç INDEXING STATUS COUNTS\n      indexing_status_counts: {\n        newly_indexed: validIndexingData.filter(p => p.indexing_status === 'newly_indexed').length,\n        deindexed: validIndexingData.filter(p => p.indexing_status === 'deindexed').length,\n        crawl_issues: validIndexingData.filter(p => p.indexing_status === 'crawl_issue').length\n      }\n    },\n    \n    // üéØ PROCESSING STATUS\n    processing_status: {\n      success: true,\n      message: 'Batch processing completed successfully',\n      records_processed: validPerformanceData.length + validIndexingData.length,\n      batch_complete: true\n    }\n  };\n  \n  // üìä Log batch processing results\n  console.log(`‚úÖ Batch Processing Complete:`);\n  console.log(`üìä Performance Records: ${validPerformanceData.length}`);\n  console.log(`üîç Indexing Records: ${validIndexingData.length}`);\n  console.log(`üéØ Total Records: ${validPerformanceData.length + validIndexingData.length}`);\n  \n  return { json: batchProcessedData };\n  \n} catch (error) {\n  // üö® Error handling for batch processing\n  console.error('‚ùå Batch Processing Error:', error.message);\n  \n  return {\n    json: {\n      performance_data: [],\n      indexing_data: [],\n      analysis_date: new Date().toISOString().split('T')[0],\n      processing_time: new Date().toISOString(),\n      batch_info: {\n        performance_records: 0,\n        indexing_records: 0,\n        total_records: 0,\n        batch_size_used: 0,\n        processing_complete: false\n      },\n      summary: {\n        total_clicks: 0,\n        total_impressions: 0,\n        avg_ctr: 0,\n        alert_counts: { traffic_drops: 0, traffic_surges: 0, low_ctr: 0, low_position: 0, potential_deindex: 0, normal: 0 },\n        indexing_status_counts: { newly_indexed: 0, deindexed: 0, crawl_issues: 0 }\n      },\n      processing_status: {\n        success: false,\n        message: `Batch processing failed: ${error.message}`,\n        records_processed: 0,\n        batch_complete: false\n      }\n    }\n  };\n}"
      },
      "id": "batch_data_processor",
      "name": "Batch Data Processor",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [900, 300],
      "notes": "üîÑ BATCH DATA PROCESSOR\n\nüéØ FEATURES:\n‚Ä¢ Null-safe data processing\n‚Ä¢ Array validation\n‚Ä¢ Error handling\n‚Ä¢ Batch statistics tracking\n\nüõ°Ô∏è SAFEGUARDS:\n‚Ä¢ Try-catch error handling\n‚Ä¢ Data type validation\n‚Ä¢ Null checks\n‚Ä¢ Array validation\n\nüìä PROCESSING:\n‚Ä¢ Combines performance and indexing data\n‚Ä¢ Calculates batch statistics\n‚Ä¢ Generates summary metrics\n‚Ä¢ Tracks processing status\n\nüîß RELIABILITY:\n‚Ä¢ Handles empty datasets\n‚Ä¢ Graceful error recovery\n‚Ä¢ Detailed logging\n‚Ä¢ Status tracking"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "leftValue": "={{ $json.processing_status.success }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equal"
              }
            },
            {
              "leftValue": "={{ $json.batch_info.total_records }}",
              "rightValue": 0,
              "operator": {
                "type": "number",
                "operation": "gt"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "data_validation_check",
      "name": "Data Validation Check",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [1120, 300],
      "notes": "‚úÖ DATA VALIDATION CHECK\n\nüéØ VALIDATION CRITERIA:\n‚Ä¢ Processing success = true\n‚Ä¢ Total records > 0\n‚Ä¢ Batch completion confirmed\n\nüîÄ FLOW CONTROL:\n‚Ä¢ TRUE: Continue to AI analysis\n‚Ä¢ FALSE: Send error notification\n\nüõ°Ô∏è SAFEGUARDS:\n‚Ä¢ Prevents empty data analysis\n‚Ä¢ Ensures data quality\n‚Ä¢ Validates processing success\n\nüìä BENEFITS:\n‚Ä¢ Avoids AI analysis on empty data\n‚Ä¢ Prevents unnecessary API calls\n‚Ä¢ Ensures report quality"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.anthropic.com/v1/messages",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "headers": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "body": {
          "parameters": [
            {
              "name": "model",
              "value": "claude-3-5-sonnet-20241022"
            },
            {
              "name": "max_tokens",
              "value": 3000
            },
            {
              "name": "messages",
              "value": "=[{\n  \"role\": \"user\",\n  \"content\": `You are an expert SEO analyst. Analyze this BATCHED Google Search Console data and provide strategic insights.\n\nüî¢ BATCH PROCESSING INFO:\n‚Ä¢ Records Processed: ${$json.batch_info.total_records}\n‚Ä¢ Performance Pages: ${$json.batch_info.performance_records}\n‚Ä¢ Indexing Issues: ${$json.batch_info.indexing_records}\n‚Ä¢ Batch Size Used: ${$json.batch_info.batch_size_used}\n‚Ä¢ Processing Status: ${$json.processing_status.success ? 'SUCCESS' : 'FAILED'}\n\nüìä SITE PERFORMANCE SUMMARY:\n‚Ä¢ Total Clicks: ${$json.summary.total_clicks.toLocaleString()}\n‚Ä¢ Total Impressions: ${$json.summary.total_impressions.toLocaleString()}\n‚Ä¢ Average CTR: ${$json.summary.avg_ctr.toFixed(2)}%\n‚Ä¢ Analysis Date: ${$json.analysis_date}\n\nüö® ALERT BREAKDOWN:\n‚Ä¢ Traffic Drops: ${$json.summary.alert_counts.traffic_drops}\n‚Ä¢ Traffic Surges: ${$json.summary.alert_counts.traffic_surges}\n‚Ä¢ Low CTR Opportunities: ${$json.summary.alert_counts.low_ctr}\n‚Ä¢ Position Improvements: ${$json.summary.alert_counts.low_position}\n‚Ä¢ Potential Deindexing: ${$json.summary.alert_counts.potential_deindex}\n‚Ä¢ Normal Pages: ${$json.summary.alert_counts.normal}\n\nüîç INDEXING STATUS:\n‚Ä¢ Newly Indexed: ${$json.summary.indexing_status_counts.newly_indexed}\n‚Ä¢ Deindexed: ${$json.summary.indexing_status_counts.deindexed}\n‚Ä¢ Crawl Issues: ${$json.summary.indexing_status_counts.crawl_issues}\n\nüìã PERFORMANCE DATA (TOP ${$json.batch_info.performance_records} PAGES):\n${JSON.stringify($json.performance_data.slice(0, 10), null, 2)}\n\nüîç INDEXING DATA (${$json.batch_info.indexing_records} ISSUES):\n${JSON.stringify($json.indexing_data.slice(0, 5), null, 2)}\n\nProvide analysis in this format:\n\nüîç **SEO WATCHDOG BATCH REPORT - ${$json.analysis_date}**\n\n**üìä BATCH PROCESSING SUMMARY:**\n‚Ä¢ Pages Analyzed: ${$json.batch_info.performance_records}\n‚Ä¢ Indexing Issues: ${$json.batch_info.indexing_records}\n‚Ä¢ Processing Status: ${$json.processing_status.success ? 'SUCCESS' : 'FAILED'}\n‚Ä¢ Data Quality: [Assessment of data completeness]\n\n**üö® CRITICAL ALERTS:**\n[List most urgent issues from the batch]\n\n**üìà TRAFFIC ANALYSIS:**\n‚Ä¢ Top Performing Pages: [Best performers from batch]\n‚Ä¢ Traffic Drops: [Pages with significant decreases]\n‚Ä¢ Growth Opportunities: [Pages with potential]\n\n**üéØ OPTIMIZATION PRIORITIES:**\n‚Ä¢ Immediate Actions: [Top 3 actions for this batch]\n‚Ä¢ CTR Improvements: [Specific low-CTR pages]\n‚Ä¢ Position Gains: [Ranking improvement opportunities]\n\n**üîç INDEXING STATUS:**\n‚Ä¢ New Additions: [Recently indexed pages]\n‚Ä¢ Issues Found: [Deindexed or crawl problems]\n‚Ä¢ Technical Actions: [Required fixes]\n\n**‚úÖ BATCH RECOMMENDATIONS:**\n1. [Action for highest-traffic pages]\n2. [Action for biggest opportunities]\n3. [Action for critical issues]\n\n**üìä NEXT BATCH PRIORITIES:**\n‚Ä¢ [What to monitor in next batch]\n‚Ä¢ [Adjustments needed]\n‚Ä¢ [Focus areas]\n\nFocus on actionable insights from this specific batch of data.`\n}]"
            }
          ]
        }
      },
      "id": "claude_batch_analysis",
      "name": "Claude AI - Batch Analysis",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [1340, 200],
      "notes": "ü§ñ CLAUDE AI BATCH ANALYSIS\n\nüéØ BATCH-OPTIMIZED FEATURES:\n‚Ä¢ Processes limited dataset efficiently\n‚Ä¢ Focuses on top-performing pages\n‚Ä¢ Provides batch-specific insights\n‚Ä¢ Handles partial data gracefully\n\nüìä ANALYSIS SCOPE:\n‚Ä¢ Top performing pages only\n‚Ä¢ Critical issues prioritized\n‚Ä¢ Actionable recommendations\n‚Ä¢ Batch-specific context\n\nüîß OPTIMIZATIONS:\n‚Ä¢ Reduced token usage\n‚Ä¢ Focused analysis\n‚Ä¢ Efficient processing\n‚Ä¢ Quality insights"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "=https://api.telegram.org/bot{{ $env.TELEGRAM_BOT_TOKEN }}/sendMessage",
        "headers": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "body": {
          "parameters": [
            {
              "name": "chat_id",
              "value": "={{ $env.TELEGRAM_CHAT_ID }}"
            },
            {
              "name": "text",
              "value": "üö® **SEO WATCHDOG - PROCESSING ERROR**\\n\\n‚ö†Ô∏è **Issue:** {{ $json.processing_status.message }}\\n\\nüìä **Status:**\\n‚Ä¢ Processing Success: {{ $json.processing_status.success }}\\n‚Ä¢ Records Processed: {{ $json.processing_status.records_processed }}\\n‚Ä¢ Batch Complete: {{ $json.processing_status.batch_complete }}\\n\\nüîß **Next Steps:**\\n‚Ä¢ Check BigQuery connection\\n‚Ä¢ Verify data availability\\n‚Ä¢ Review batch configuration\\n‚Ä¢ Check environment variables\\n\\n‚è∞ **Time:** {{ $json.processing_time }}\\n\\nüîÑ **Next Attempt:** Tomorrow at 9 AM"
            },
            {
              "name": "parse_mode",
              "value": "Markdown"
            }
          ]
        }
      },
      "id": "error_notification",
      "name": "Error Notification",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [1340, 400],
      "notes": "üö® ERROR NOTIFICATION\n\nüéØ PURPOSE:\n‚Ä¢ Notifies about processing failures\n‚Ä¢ Provides error details\n‚Ä¢ Suggests troubleshooting steps\n‚Ä¢ Maintains monitoring continuity\n\nüìã ERROR INFO:\n‚Ä¢ Processing status\n‚Ä¢ Record counts\n‚Ä¢ Error messages\n‚Ä¢ Timestamp\n\nüîß TROUBLESHOOTING:\n‚Ä¢ Connection checks\n‚Ä¢ Data availability\n‚Ä¢ Configuration review\n‚Ä¢ Environment validation"
    },
    {
      "parameters": {
        "jsCode": "// üì± ENHANCED TELEGRAM FORMATTING FOR BATCH REPORTS\n// Optimized for batch processing context\n\nconst response = $json.content[0].text;\n\n// üéØ Enhanced formatting with batch context\nconst formatForTelegram = {\n  report: response,\n  timestamp: new Date().toISOString(),\n  date_readable: new Date().toLocaleDateString('en-US', {\n    weekday: 'long',\n    year: 'numeric',\n    month: 'long',\n    day: 'numeric'\n  }),\n  chat_id: $env.TELEGRAM_CHAT_ID,\n  parse_mode: 'Markdown',\n  disable_web_page_preview: true,\n  disable_notification: false,\n  \n  // üìä BATCH-SPECIFIC METADATA\n  batch_metadata: {\n    processing_type: 'BATCH',\n    character_count: response.length,\n    word_count: response.split(' ').length,\n    report_quality: response.length > 500 ? 'COMPREHENSIVE' : 'BASIC',\n    batch_processing: true\n  }\n};\n\nreturn { json: formatForTelegram };"
      },
      "id": "format_batch_report",
      "name": "Format Batch Report",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1560, 200],
      "notes": "üì± BATCH REPORT FORMATTING\n\nüéØ BATCH-SPECIFIC FEATURES:\n‚Ä¢ Batch processing context\n‚Ä¢ Optimized message length\n‚Ä¢ Quality assessment\n‚Ä¢ Metadata tracking\n\nüìä ENHANCEMENTS:\n‚Ä¢ Batch processing indicators\n‚Ä¢ Report quality metrics\n‚Ä¢ Character counting\n‚Ä¢ Processing type labeling\n\nüîß TELEGRAM OPTIMIZATION:\n‚Ä¢ Markdown formatting\n‚Ä¢ Web preview disabled\n‚Ä¢ Notification enabled\n‚Ä¢ Mobile-friendly layout"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "=https://api.telegram.org/bot{{ $env.TELEGRAM_BOT_TOKEN }}/sendMessage",
        "headers": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "body": {
          "parameters": [
            {
              "name": "chat_id",
              "value": "={{ $json.chat_id }}"
            },
            {
              "name": "text",
              "value": "={{ $json.report }}"
            },
            {
              "name": "parse_mode",
              "value": "={{ $json.parse_mode }}"
            },
            {
              "name": "disable_web_page_preview",
              "value": "={{ $json.disable_web_page_preview }}"
            },
            {
              "name": "disable_notification",
              "value": "={{ $json.disable_notification }}"
            }
          ]
        }
      },
      "id": "send_batch_report",
      "name": "Send Batch Report",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [1780, 200],
      "notes": "üì± BATCH REPORT DELIVERY\n\nüéØ OPTIMIZED DELIVERY:\n‚Ä¢ Batch processing context\n‚Ä¢ Efficient message size\n‚Ä¢ Quality formatting\n‚Ä¢ Reliable delivery\n\nüìä FEATURES:\n‚Ä¢ Markdown support\n‚Ä¢ Mobile optimization\n‚Ä¢ Notification control\n‚Ä¢ Preview management\n\nüîß RELIABILITY:\n‚Ä¢ Error handling\n‚Ä¢ Retry capability\n‚Ä¢ Status tracking\n‚Ä¢ Delivery confirmation"
    },
    {
      "parameters": {
        "jsCode": "// üìä BATCH PROCESSING RESULT LOGGER\n// Enhanced logging for batch processing workflows\n\nconst success = $json.ok;\nconst messageId = $json.message_id;\nconst errorDescription = $json.description;\n\nconst timestamp = new Date().toISOString();\nconst readableTime = new Date().toLocaleString('en-US', {\n  timeZone: 'UTC',\n  weekday: 'long',\n  year: 'numeric',\n  month: 'long', \n  day: 'numeric',\n  hour: '2-digit',\n  minute: '2-digit',\n  second: '2-digit'\n});\n\n// üìä Enhanced batch processing logs\nif (success) {\n  console.log(`‚úÖ BATCH SEO REPORT DELIVERED SUCCESSFULLY`);\n  console.log(`üì± Telegram Message ID: ${messageId}`);\n  console.log(`‚è∞ Delivery Time: ${readableTime}`);\n  console.log(`üî¢ Processing Mode: BATCH`);\n  console.log(`üéØ Report Status: DELIVERED`);\n  console.log(`üìä Batch Processing: COMPLETE`);\n} else {\n  console.log(`‚ùå BATCH SEO REPORT DELIVERY FAILED`);\n  console.log(`‚ö†Ô∏è Error: ${errorDescription}`);\n  console.log(`‚è∞ Failed At: ${readableTime}`);\n  console.log(`üî¢ Processing Mode: BATCH`);\n  console.log(`üéØ Report Status: FAILED`);\n}\n\n// üîç Batch processing summary\nconsole.log(`üìã Workflow: SEO Watchdog Batch Processing`);\nconsole.log(`üîÑ Process: Daily Batch Analysis Complete`);\nconsole.log(`üìà Next Batch: Tomorrow at 9 AM`);\nconsole.log(`üéØ Batch Size: Optimized for performance`);\n\nreturn { \n  json: {\n    success: success,\n    message_id: messageId,\n    error_description: errorDescription,\n    timestamp: timestamp,\n    readable_time: readableTime,\n    processing_mode: 'BATCH',\n    workflow_status: success ? 'BATCH_COMPLETED' : 'BATCH_FAILED',\n    next_execution: 'Tomorrow at 9 AM',\n    batch_processing: true,\n    summary: {\n      process: 'SEO Watchdog Batch Analysis',\n      status: success ? 'SUCCESS' : 'FAILED',\n      delivery_method: 'Telegram',\n      completion_time: readableTime,\n      processing_type: 'BATCHED'\n    }\n  }\n};"
      },
      "id": "log_batch_result",
      "name": "Log Batch Result",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [2000, 200],
      "notes": "üìä BATCH RESULT LOGGING\n\nüéØ BATCH-SPECIFIC LOGGING:\n‚Ä¢ Processing mode tracking\n‚Ä¢ Batch completion status\n‚Ä¢ Performance metrics\n‚Ä¢ Delivery confirmation\n\nüìã LOG FEATURES:\n‚Ä¢ Success/failure status\n‚Ä¢ Message ID tracking\n‚Ä¢ Error description\n‚Ä¢ Processing mode indicator\n‚Ä¢ Batch completion confirmation\n\nüîç MONITORING:\n‚Ä¢ Batch processing health\n‚Ä¢ Delivery reliability\n‚Ä¢ Performance tracking\n‚Ä¢ Error analysis\n\nüìä WORKFLOW SUMMARY:\n‚Ä¢ Process completion\n‚Ä¢ Next execution schedule\n‚Ä¢ Batch size optimization\n‚Ä¢ Performance status"
    }
  ],
  "connections": {
    "Daily Schedule": {
      "main": [
        [
          {
            "node": "Batch Configuration",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Batch Configuration": {
      "main": [
        [
          {
            "node": "BigQuery - Performance (Batched)",
            "type": "main",
            "index": 0
          },
          {
            "node": "BigQuery - Indexing (Batched)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "BigQuery - Performance (Batched)": {
      "main": [
        [
          {
            "node": "Batch Data Processor",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "BigQuery - Indexing (Batched)": {
      "main": [
        [
          {
            "node": "Batch Data Processor",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Batch Data Processor": {
      "main": [
        [
          {
            "node": "Data Validation Check",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Data Validation Check": {
      "main": [
        [
          {
            "node": "Claude AI - Batch Analysis",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Error Notification",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Claude AI - Batch Analysis": {
      "main": [
        [
          {
            "node": "Format Batch Report",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Batch Report": {
      "main": [
        [
          {
            "node": "Send Batch Report",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Send Batch Report": {
      "main": [
        [
          {
            "node": "Log Batch Result",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1",
    "saveManualExecutions": true,
    "callerPolicy": "workflowsFromSameOwner",
    "timeouts": {
      "default": 30000,
      "max": 60000
    },
    "errorWorkflow": {
      "enabled": false
    }
  },
  "staticData": null,
  "tags": [
    {
      "createdAt": "2024-12-07T00:00:00.000Z",
      "updatedAt": "2024-12-07T00:00:00.000Z",
      "id": "seo-batch",
      "name": "SEO Batch"
    },
    {
      "createdAt": "2024-12-07T00:00:00.000Z",
      "updatedAt": "2024-12-07T00:00:00.000Z",
      "id": "optimized",
      "name": "Optimized"
    },
    {
      "createdAt": "2024-12-07T00:00:00.000Z",
      "updatedAt": "2024-12-07T00:00:00.000Z",
      "id": "performance",
      "name": "Performance"
    }
  ],
  "triggerCount": 1,
  "updatedAt": "2024-12-07T00:00:00.000Z",
  "versionId": "2.1-batched"
}